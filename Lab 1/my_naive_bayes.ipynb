{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing necessary libraries and opening text files\n",
    "import math as m\n",
    "import random\n",
    "trainFile1 = open('C:/Users/hp/Desktop/Maame School/Year 3 Sem 1/Natural Language Processing/NLP-18-maameyaa18/Lab 1/sentiment labelled sentences/amazon_cells_labelled.txt', 'r')\n",
    "trainFile2 = open('C:/Users/hp/Desktop/Maame School/Year 3 Sem 1/Natural Language Processing/NLP-18-maameyaa18/Lab 1/sentiment labelled sentences/imdb_labelled.txt', 'r')\n",
    "trainFile3 = open('C:/Users/hp/Desktop/Maame School/Year 3 Sem 1/Natural Language Processing/NLP-18-maameyaa18/Lab 1/sentiment labelled sentences/yelp_labelled.txt', 'r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Function to split into training and test data\n",
    "def splitToData(*files):\n",
    "    data =[]\n",
    "    for file in files:\n",
    "        for line in file:\n",
    "            cleanLine = line.rstrip('\\n').split('\\t')\n",
    "            sentence = cleanLine[0]\n",
    "            features = sentence.split(' ')\n",
    "            tag = cleanLine[1]\n",
    "            pair = (features,tag)\n",
    "            data.append(pair)\n",
    "    random.shuffle(data)\n",
    "    trainingData= data[0:int(0.8*len(data))]\n",
    "    testData = data[int(0.8*len(data)):]\n",
    "    return (trainingData, testData)\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to split .txt file positive and negative bags of words as well as list of classes\n",
    "def splitToBags(trainList):\n",
    "    positive =[]\n",
    "    negative =[]\n",
    "    classes = []\n",
    "    for i in range (len(trainList)):\n",
    "        classes.append(trainList[i][1])\n",
    "        if trainList[i][1]== '1':\n",
    "            positive+= [i.lower() for i in (trainList[i][0])]\n",
    "        elif trainList[i][1]== '0':\n",
    "            negative+= [j.lower() for j in(trainList[i][0])]\n",
    "    return (negative, positive, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fuction that loops through positive and negative words to create vocabulary of unique words\n",
    "def createVocabulary(bag1,bag2):\n",
    "    vocabulary =[]\n",
    "    for word in bag1:\n",
    "        if word not in vocabulary:\n",
    "            vocabulary.append(word)\n",
    "    for word in bag2:\n",
    "        if word not in vocabulary:\n",
    "            vocabulary.append(word)\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Storing the frequency of each word in both classes in a dictionary\n",
    "def createFreqLookup(negWords,posWords):\n",
    "    freqLookup ={}\n",
    "    for word in posWords:\n",
    "        freqLookup[(word,1)] = posWords.count(word)\n",
    "        freqLookup[(word,0)] = negWords.count(word)\n",
    "            \n",
    "    for word in negWords:\n",
    "        freqLookup[(word,1)] = posWords.count(word)\n",
    "        freqLookup[(word,0)] = negWords.count(word)\n",
    "    return freqLookup   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to calculate for the prior probability of the classes\n",
    "def calculateLogPriors(classArray):\n",
    "    negClass =[]\n",
    "    for i in classArray:\n",
    "        if int(i) == 0:\n",
    "            negClass.append(1)\n",
    "    negProb = sum(negClass)/len(classArray)\n",
    "    posProb = 1-negProb\n",
    "    negPrior = m.log10(negProb)\n",
    "    posPrior = m.log10(posProb)\n",
    "    return (negPrior,posPrior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400\n",
      "15319\n",
      "14691\n",
      "6355\n",
      "-0.2945639534147495\n",
      "-0.30759376516636944\n"
     ]
    }
   ],
   "source": [
    "#Storing counts of words in each class in a dictionary\n",
    "\n",
    "def main():\n",
    "    trainValues,testValues = splitToData(trainFile1,trainFile2,trainFile3)\n",
    "    print(len(trainValues))\n",
    "    negBag,posBag,classList= splitToBags(trainValues)\n",
    "    print(len(negBag))\n",
    "    print(len(posBag))\n",
    "    vocabularyBag = createVocabulary(negBag,posBag)\n",
    "    print(len(vocabularyBag))\n",
    "    countLookup = createFreqLookup(negBag,posBag)\n",
    "    prior0,prior1 = calculateLogPriors(classList)\n",
    "    print(prior0)\n",
    "    print(prior1)\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
